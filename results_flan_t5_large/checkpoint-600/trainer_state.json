{
  "best_global_step": 300,
  "best_metric": 7.128509423637297e-06,
  "best_model_checkpoint": "./results_flan_t5_large/checkpoint-200",
  "epoch": 0.9836065573770492,
  "eval_steps": 100,
  "global_step": 600,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.001639344262295082,
      "grad_norm": 0.4114435017108917,
      "learning_rate": 0.0003,
      "loss": 0.3899,
      "step": 1
    },
    {
      "epoch": 0.040983606557377046,
      "grad_norm": 0.17916153371334076,
      "learning_rate": 0.0002881967213114754,
      "loss": 0.2108,
      "step": 25
    },
    {
      "epoch": 0.08196721311475409,
      "grad_norm": 0.14406777918338776,
      "learning_rate": 0.00027590163934426227,
      "loss": 0.0028,
      "step": 50
    },
    {
      "epoch": 0.12295081967213115,
      "grad_norm": 0.011716814711689949,
      "learning_rate": 0.00026360655737704913,
      "loss": 0.0028,
      "step": 75
    },
    {
      "epoch": 0.16393442622950818,
      "grad_norm": 0.0059103770181536674,
      "learning_rate": 0.00025131147540983606,
      "loss": 0.0009,
      "step": 100
    },
    {
      "epoch": 0.16393442622950818,
      "eval_loss": 5.3233732614899054e-05,
      "eval_runtime": 5.5603,
      "eval_samples_per_second": 109.706,
      "eval_steps_per_second": 13.848,
      "step": 100
    },
    {
      "epoch": 0.20491803278688525,
      "grad_norm": 0.001139309024438262,
      "learning_rate": 0.00023901639344262293,
      "loss": 0.0008,
      "step": 125
    },
    {
      "epoch": 0.2459016393442623,
      "grad_norm": 0.020749486982822418,
      "learning_rate": 0.00022672131147540982,
      "loss": 0.0017,
      "step": 150
    },
    {
      "epoch": 0.28688524590163933,
      "grad_norm": 0.0012028294149786234,
      "learning_rate": 0.0002144262295081967,
      "loss": 0.0003,
      "step": 175
    },
    {
      "epoch": 0.32786885245901637,
      "grad_norm": 0.34873783588409424,
      "learning_rate": 0.00020213114754098356,
      "loss": 0.0008,
      "step": 200
    },
    {
      "epoch": 0.32786885245901637,
      "eval_loss": 1.230636644322658e-05,
      "eval_runtime": 5.6129,
      "eval_samples_per_second": 108.678,
      "eval_steps_per_second": 13.718,
      "step": 200
    },
    {
      "epoch": 0.36885245901639346,
      "grad_norm": 0.009860372170805931,
      "learning_rate": 0.00018983606557377048,
      "loss": 0.0008,
      "step": 225
    },
    {
      "epoch": 0.4098360655737705,
      "grad_norm": 0.004029999021440744,
      "learning_rate": 0.00017754098360655735,
      "loss": 0.0002,
      "step": 250
    },
    {
      "epoch": 0.45081967213114754,
      "grad_norm": 0.001786216627806425,
      "learning_rate": 0.00016524590163934425,
      "loss": 0.0002,
      "step": 275
    },
    {
      "epoch": 0.4918032786885246,
      "grad_norm": 0.0033768583089113235,
      "learning_rate": 0.00015295081967213112,
      "loss": 0.0053,
      "step": 300
    },
    {
      "epoch": 0.4918032786885246,
      "eval_loss": 7.128509423637297e-06,
      "eval_runtime": 5.6458,
      "eval_samples_per_second": 108.044,
      "eval_steps_per_second": 13.638,
      "step": 300
    },
    {
      "epoch": 0.5327868852459017,
      "grad_norm": 0.0019237520173192024,
      "learning_rate": 0.00014065573770491801,
      "loss": 0.0005,
      "step": 325
    },
    {
      "epoch": 0.5737704918032787,
      "grad_norm": 0.0009274366311728954,
      "learning_rate": 0.0001283606557377049,
      "loss": 0.0004,
      "step": 350
    },
    {
      "epoch": 0.6147540983606558,
      "grad_norm": 0.0008284724317491055,
      "learning_rate": 0.00011606557377049179,
      "loss": 0.0039,
      "step": 375
    },
    {
      "epoch": 0.6557377049180327,
      "grad_norm": 0.0033529235515743494,
      "learning_rate": 0.00010377049180327867,
      "loss": 0.0004,
      "step": 400
    },
    {
      "epoch": 0.6557377049180327,
      "eval_loss": 3.0528106435667723e-05,
      "eval_runtime": 5.6477,
      "eval_samples_per_second": 108.008,
      "eval_steps_per_second": 13.634,
      "step": 400
    },
    {
      "epoch": 0.6967213114754098,
      "grad_norm": 0.0051621682941913605,
      "learning_rate": 9.147540983606556e-05,
      "loss": 0.0002,
      "step": 425
    },
    {
      "epoch": 0.7377049180327869,
      "grad_norm": 0.0070550646632909775,
      "learning_rate": 7.918032786885245e-05,
      "loss": 0.0003,
      "step": 450
    },
    {
      "epoch": 0.7786885245901639,
      "grad_norm": 0.0026204704772681,
      "learning_rate": 6.688524590163934e-05,
      "loss": 0.0009,
      "step": 475
    },
    {
      "epoch": 0.819672131147541,
      "grad_norm": 0.0016837944276630878,
      "learning_rate": 5.4590163934426226e-05,
      "loss": 0.0004,
      "step": 500
    },
    {
      "epoch": 0.819672131147541,
      "eval_loss": 1.1017698852811009e-05,
      "eval_runtime": 5.6548,
      "eval_samples_per_second": 107.873,
      "eval_steps_per_second": 13.617,
      "step": 500
    },
    {
      "epoch": 0.860655737704918,
      "grad_norm": 0.0019141027005389333,
      "learning_rate": 4.229508196721311e-05,
      "loss": 0.0001,
      "step": 525
    },
    {
      "epoch": 0.9016393442622951,
      "grad_norm": 0.001230353256687522,
      "learning_rate": 2.9999999999999997e-05,
      "loss": 0.0001,
      "step": 550
    },
    {
      "epoch": 0.9426229508196722,
      "grad_norm": 0.0007460353663191199,
      "learning_rate": 1.7704918032786883e-05,
      "loss": 0.0001,
      "step": 575
    },
    {
      "epoch": 0.9836065573770492,
      "grad_norm": 0.006774600129574537,
      "learning_rate": 5.40983606557377e-06,
      "loss": 0.0003,
      "step": 600
    },
    {
      "epoch": 0.9836065573770492,
      "eval_loss": 8.36762319522677e-06,
      "eval_runtime": 5.6558,
      "eval_samples_per_second": 107.854,
      "eval_steps_per_second": 13.614,
      "step": 600
    }
  ],
  "logging_steps": 25,
  "max_steps": 610,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1,
  "save_steps": 200,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 1051872048009216.0,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
